// Copyright 2025 Jiri Bobek. All rights reserved.
// License: GPL 3.0 or later. See LICENSE.txt for details.

use super::super::rms_norm::*;

use crate::debug_2d;
use crate::nn::EvalContext;
use crate::nn::layers::Layer;
use crate::tensor::device::cpu::CPUDevice;
use crate::tensor::{self, Tensor};

// Note: The expected tensors were generated by gen_test_data.py

#[test]
fn test_rms_norm() {
	let rms_norm = RMSNorm::new(5, 1e-5);
	let dev = CPUDevice::new("CPU".to_string());

	#[rustfmt::skip] let inp = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[-1.2719, -0.6884, -0.6477, -1.3343, -1.7648],
			[-1.9440,  0.9989,  2.8260, -0.3503, -0.5406],
			[ 0.1619, -0.9744, -0.6539,  1.9764,  0.7423],
			[ 0.0689,  1.1983,  0.0077, -0.6580, -0.4917],
		]
	);

	#[rustfmt::skip] let expected_out = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[-1.0451, -0.5656, -0.5322, -1.0963, -1.4501],
			[-1.1974,  0.6153,  1.7407, -0.2158, -0.3330],
			[ 0.1495, -0.9000, -0.6040,  1.8255,  0.6856],
			[ 0.1059,  1.8422,  0.0118, -1.0116, -0.7559],
		]
	);

	let mut ctx = EvalContext::new(true);
	let out = rms_norm.forward(inp.clone(), &mut ctx);

	assert!(tensor::math::approx_eq(&out, &expected_out, 1e-4));

	#[rustfmt::skip] let d_out = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[ 0.1000,  0.2000, -0.3000, -0.1000,  0.7000],
			[ 0.0500, -0.1500,  0.1000,  0.0000,  0.6500],
			[-0.2000,  0.1000,  0.0500,  0.0500,  0.3331],
			[ 0.0000,  0.1000, -0.0500, -0.0500, -0.1442],
		]
	);

	#[rustfmt::skip] let expected_d_inp = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[-0.0833,  0.0748, -0.3308, -0.2557,  0.3456],
			[ 0.0021, -0.0776,  0.1033, -0.0052,  0.3924],
			[-0.1894,  0.1206,  0.0651, -0.0110,  0.2862],
			[-0.0112, -0.0407, -0.0781,  0.0299, -0.1419],
		]
	);

	let d_inp = rms_norm.backward(d_out.clone(), &mut ctx);

	println!("d_inp = {d_inp}");
	println!("expected_d_inp = {expected_d_inp}");

	assert!(tensor::math::approx_eq(&d_inp, &expected_d_inp, 1e-4));
}
