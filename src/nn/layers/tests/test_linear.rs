// Copyright 2025 Jiri Bobek. All rights reserved.
// License: GPL 3.0 or later. See LICENSE.txt for details.

use super::super::linear::*;

use crate::data2d;
use crate::nn::layers::Layer;
use crate::nn::{EvalContext, ModelContext};
use crate::tensor::device::cpu::CPUDevice;
use crate::tensor::math::Savable;
use crate::tensor::{self, DType, Tensor};

// Note: The expected tensors were generated by gen_test_data.py

#[test]
fn test_linear() {
	let dev = CPUDevice::new("CPU".to_string());
	let mut model_ctx = ModelContext::new(dev.clone());
	let linear = Linear::new(4, 3, DType::F32, &mut model_ctx);

	#[rustfmt::skip] linear.weights.borrow().value().fill_2d(
		data2d![
			[ 0.7667,  1.6273,  1.2086, -0.1605],
			[-0.1392,  1.3587, -0.4759, -0.3494],
			[ 0.4811,  0.6726,  0.7888, -0.9647],
		]
	);

	#[rustfmt::skip] let inp = Tensor::new_2d::<f32>(
		dev.clone(),
		data2d![
			[ 0.0555, -0.7310,  0.7083, -0.7139],
			[ 0.1544, -0.9952, -1.5667,  2.1498],
			[ 0.1712,  0.3175, -1.3459, -0.4934],
			[ 0.8266, -0.7996,  0.1596,  2.2111],
			[-0.0516,  0.2001,  0.6081,  1.2414],
		]
	);

	#[rustfmt::skip] let expected_out = Tensor::new_2d::<f32>(
		dev.clone(),
		data2d![
			[-1.0451, -0.5656, -0.5322, -1.0963, -1.4501],
			[-1.1974,  0.6153,  1.7407, -0.2158, -0.3330],
			[ 0.1495, -0.9000, -0.6040,  1.8255,  0.6856],
			[ 0.1059,  1.8422,  0.0118, -1.0116, -0.7559],
		]
	);

	let mut ctx = EvalContext::new(true);
	let out = expected_out.new_empty_like();
	linear.forward(inp.clone(), &mut ctx).save_to(&out);

	assert!(tensor::math::approx_eq(&out, &expected_out, 1e-4));

	#[rustfmt::skip] let d_out = Tensor::new_2d::<f32>(
		dev.clone(),
		data2d![
			[ 0.1000,  0.2000, -0.3000, -0.1000,  0.7000],
			[ 0.0500, -0.1500,  0.1000,  0.0000,  0.6500],
			[-0.2000,  0.1000,  0.0500,  0.0500,  0.3331],
			[ 0.0000,  0.1000, -0.0500, -0.0500, -0.1442],
		]
	);

	#[rustfmt::skip] let expected_d_inp = Tensor::new_2d::<f32>(
		dev.clone(),
		data2d![
			[-0.0833,  0.0748, -0.3308, -0.2557,  0.3456],
			[ 0.0021, -0.0776,  0.1033, -0.0052,  0.3924],
			[-0.1894,  0.1206,  0.0651, -0.0110,  0.2862],
			[-0.0112, -0.0407, -0.0781,  0.0299, -0.1419],
		]
	);

	let d_inp = expected_d_inp.new_empty_like();
	linear.backward(d_out.clone(), &mut ctx).save_to(&d_inp);

	println!("d_inp = {d_inp}");
	println!("expected_d_inp = {expected_d_inp}");

	assert!(tensor::math::approx_eq(&d_inp, &expected_d_inp, 1e-4));
}
