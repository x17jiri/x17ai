// Copyright 2025 Jiri Bobek. All rights reserved.
// License: GPL 3.0 or later. See LICENSE.txt for details.

use super::super::linear::*;

use crate::nn::layers::Layer;
use crate::nn::{EvalContext, ModelContext};
use crate::tensor::device::cpu::CPUDevice;
use crate::tensor::{self, HasDType, Tensor};
use crate::{debug_2d, debug_3d};

// Note: The expected tensors were generated by gen_test_data.py

// TODO - test also d_weights

#[test]
fn test_linear() {
	let dev = CPUDevice::new("CPU".to_string());
	let mut model_ctx = ModelContext::new(dev.clone());
	let linear = Linear::new(5, 6, f32::dtype, &mut model_ctx);

	#[rustfmt::skip] linear.weights.borrow().value().fill_debug_2d(
		debug_2d![
			f32;
			[-0.7392, -0.4243, -2.2199, -0.7662, -0.4344],
			[-1.1176, -0.5131,  0.5884,  1.6860, -0.5456],
			[-0.6692, -0.7482, -0.5937, -0.4305, -1.6972],
			[ 1.0881, -0.7972, -1.2000, -0.6788, -0.9008],
			[ 1.8882, -1.1999,  0.3821, -0.2152,  0.2094],
			[-1.1796, -1.8167,  1.2314, -0.6760,  0.0761],
		]
	);

	#[rustfmt::skip] let inp = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[-1.2794, -0.1038,  0.3636, -0.0918, -0.6903],
			[-0.2495, -1.7407, -0.4136,  1.2375,  0.0408],
			[ 0.2060, -1.0269,  0.2663,  1.8425,  1.4105],
			[-1.8738,  1.0913,  0.5786, -0.8210,  0.0362],
		]
	);

	#[rustfmt::skip] let expected_out = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[ 0.2472,  0.8582,  0.8627, -0.4747, -1.0183,  0.9638],
			[ 0.3914,  1.3384,  0.4977,  0.3290,  0.5374,  0.9454],
			[-1.0430,  1.2478, -1.2141, -0.8041,  0.7253,  0.3633],
			[ 0.1122,  0.2105,  0.1726, -1.3767, -1.9866,  0.6699],
		]
	);

	let mut ctx = EvalContext::new(true);
	let out = linear.forward(inp.clone(), &mut ctx);

	println!("out = {out}");
	println!("expected_out = {expected_out}");

	assert!(tensor::math::approx_eq(&out, &expected_out, 1e-4));

	#[rustfmt::skip] let d_out = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[-1.2192,  0.9470, -1.0698,  1.0365,  0.1644, -0.1481],
			[-1.0424, -0.4814, -1.5834,  0.4658,  1.0362, -0.2995],
			[-0.5644,  1.4450, -1.0186, -0.5245,  2.2684, -0.5567],
			[-0.9963, -1.7835,  0.6185,  2.0077, -0.5136, -0.9927],
		]
	);

	#[rustfmt::skip] let expected_d_inp = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[ 0.8866,  0.0316,  1.0351,  0.9604,  0.3748],
			[ 2.1167,  0.3280,  0.9957,  0.1355,  1.2972],
			[ 1.5730, -0.4214,  1.4364,  1.4499,  0.8535],
			[ 1.9194,  0.6917, -1.2381, -1.2619, -0.6677],
		]
	);

	let d_inp = linear.backward(d_out.clone(), &mut ctx);

	println!("d_inp = {d_inp}");
	println!("expected_d_inp = {expected_d_inp}");

	assert!(tensor::math::approx_eq(&d_inp, &expected_d_inp, 1e-4));
}

#[test]
fn test_multihead_linear() {
	let dev = CPUDevice::new("CPU".to_string());
	let mut model_ctx = ModelContext::new(dev.clone());
	let linear = MultiheadLinear::new(5, 3, 2, f32::dtype, &mut model_ctx);

	#[rustfmt::skip] linear.linear.weights.borrow().value().fill_debug_2d(
		debug_2d![
			f32;
			[-0.7392, -0.4243, -2.2199, -0.7662, -0.4344],
			[-1.1176, -0.5131,  0.5884,  1.6860, -0.5456],
			[-0.6692, -0.7482, -0.5937, -0.4305, -1.6972],
			[ 1.0881, -0.7972, -1.2000, -0.6788, -0.9008],
			[ 1.8882, -1.1999,  0.3821, -0.2152,  0.2094],
			[-1.1796, -1.8167,  1.2314, -0.6760,  0.0761],
		]
	);

	#[rustfmt::skip] let inp = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[-1.2794, -0.1038,  0.3636, -0.0918, -0.6903],
			[-0.2495, -1.7407, -0.4136,  1.2375,  0.0408],
			[ 0.2060, -1.0269,  0.2663,  1.8425,  1.4105],
			[-1.8738,  1.0913,  0.5786, -0.8210,  0.0362],
		]
	);

	#[rustfmt::skip] let expected_out = Tensor::new_debug_3d(
		dev.clone(),
		debug_3d![
			f32;
			[ [ 0.2472,  0.8582,  0.8627], [-0.4747, -1.0183,  0.9638] ],
			[ [ 0.3914,  1.3384,  0.4977], [ 0.3290,  0.5374,  0.9454] ],
			[ [-1.0430,  1.2478, -1.2141], [-0.8041,  0.7253,  0.3633] ],
			[ [ 0.1122,  0.2105,  0.1726], [-1.3767, -1.9866,  0.6699] ],
		]
	);

	let mut ctx = EvalContext::new(true);
	let out = linear.forward(inp.clone(), &mut ctx);

	println!("out = {out}");
	println!("expected_out = {expected_out}");

	assert!(tensor::math::approx_eq(&out, &expected_out, 1e-4));

	#[rustfmt::skip] let d_out = Tensor::new_debug_3d(
		dev.clone(),
		debug_3d![
			f32;
			[ [-1.2192,  0.9470, -1.0698], [ 1.0365,  0.1644, -0.1481] ],
			[ [-1.0424, -0.4814, -1.5834], [ 0.4658,  1.0362, -0.2995] ],
			[ [-0.5644,  1.4450, -1.0186], [-0.5245,  2.2684, -0.5567] ],
			[ [-0.9963, -1.7835,  0.6185], [ 2.0077, -0.5136, -0.9927] ],
		]
	);

	#[rustfmt::skip] let expected_d_inp = Tensor::new_debug_2d(
		dev.clone(),
		debug_2d![
			f32;
			[ 1.2538,  0.0446,  1.4639,  1.3582,  0.5301],
			[ 2.9935,  0.4639,  1.4082,  0.1917,  1.8345],
			[ 2.2246, -0.5959,  2.0314,  2.0504,  1.2070],
			[ 2.7145,  0.9782, -1.7510, -1.7847, -0.9442],
		]
	);

	let d_inp = linear.backward(d_out.clone(), &mut ctx);

	println!("d_inp = {d_inp}");
	println!("expected_d_inp = {expected_d_inp}");

	assert!(tensor::math::approx_eq(&d_inp, &expected_d_inp, 1e-4));
}
